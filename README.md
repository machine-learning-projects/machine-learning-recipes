# machine-learning-recipes
Machine Learning Recipes with Josh Gordon

My code following the [Machine Learning Recipes with Josh Gordon](https://www.youtube.com/playlist?list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal) series by [Google Developers](https://www.youtube.com/user/GoogleDevelopers).

## [Part 1 - Hello World](https://youtu.be/cKxRvEZd3Mw)
Six lines of Python is all it takes to write your first machine learning program! In this episode, we'll briefly introduce what machine learning is and why it's important. Then, we'll follow a recipe for supervised learning (a technique to create a classifier from examples) and code it up.

## [Part 2 - Visualizing a Decision Tree](https://youtu.be/tNa99PG8hR8)
Last episode, we treated our Decision Tree as a blackbox. In this episode, we'll build one on a real dataset, add code to visualize it, and practice reading it - so you can see how it works under the hood.

## [Part 3 - What Makes a Good Feature?](https://youtu.be/N9fDIAflCMY)
Good features are informative, independent, and simple. In this episode, we'll introduce these concepts by using a histogram to visualize a feature from a toy dataset.

## [Part 4 - Let’s Write a Pipeline](https://youtu.be/84gqSbLcBFE)
In this episode, we’ll write a basic pipeline for supervised learning with just 12 lines of code. Along the way, we'll talk about training and testing data. Then, we’ll work on our intuition for what it means to “learn” from data.

## [Part 5 - Writing Our First Classifier](https://youtu.be/AoeEHqVSNOw)
Welcome back! It's time to write our first classifier. This is a milestone if you’re new to machine learning. We'll start with our code from episode #4 and comment out the classifier we imported. Then, we'll code up a simple replacement - using a scrappy version of k-Nearest Neighbors

## [Part 6 - Train an Image Classifier with TensorFlow for Poets](https://youtu.be/cSKfRcEDGUs)
Monet or Picasso? In this episode, we’ll train our own image classifier, using TensorFlow for Poets. Along the way, I’ll introduce Deep Learning, and add context and background on why the classifier works so well. Here are links to learn more, thanks for watching, and have fun!
